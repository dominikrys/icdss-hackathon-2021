{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Hack - Crop Yield Challenge\n",
    "\n",
    "**Challenge Description:**\n",
    "\n",
    "For this challenge, you will be tackling one of the world's most important challenges: modelling crop yields. Climate change is having a big impact in global food security, whilst Earth's population, in particular, in the developing world, continues to grow. Extreme weather events can have significant [impacts](http://www.nature.com/articles/nclimate1832) on crops and there is (significant evidence)[https://www.metoffice.gov.uk/weather/climate/climate-and-extreme-weather] showing that, recently, extreme events have become (1) more extreme and (2) more frequent, making crop yield modelling a useful tool for policy makers and suppliers who are hoping to mitigate these devastating risks.\n",
    "\n",
    "From a machine learning and statistical perspective, crop yield modelling is a challenging task that can be seen as a **weakly supervised learning** or **multiple instance learning** problem. For every year and census region (e.g. county), we can gather an abundance of features such as daily temperature, vegetation indices and soil moisture, but we only have access to 1 crop yield label. To perform regression, one usually requires the dataset $\\{(x_i,y_i)\\}_{i=1}^n$. In this case, however, we have $\\{(\\{x_{ij}\\}_{j=1}^{N_i},y_i)\\}_{i=1}^n$, where $N_i$ is the number of feature vectors available for label $y_i$. A naive approach would be to reduce to the former by averaging the covariates $\\bar{x}_{i}=\\sum_{j=1}^{N_i} x_{ij}$, but this may result in an enormous loss of information. \n",
    "\n",
    "Could you explore different approaches to modelling crop yields using the provided datasets?\n",
    "\n",
    "**Data:**\n",
    "\n",
    "You are provided with various cleaned datasets that are extracted from the State of Illinois, USA. \n",
    "\n",
    "- [ ] `IL_yield.csv` contains corn yields for various census counties in Illinois\n",
    "- [ ] `illinois-counties.geojson` contains the geometries of counties in Illinois\n",
    "- [ ] `EVI.csv` contains [Enhanced Vegetation Indices](https://en.wikipedia.org/wiki/Enhanced_vegetation_index) for pixels extract from [The Terra Moderate Resolution Imaging Spectroradiometer (MODIS) Vegetation Indices (MOD13Q1)](https://lpdaac.usgs.gov/products/mod13q1v006/) product, aggregated at the resolution of the pixels in the [The Terra and Aqua combined Moderate Resolution Imaging Spectroradiometer (MODIS) Land Cover Climate Modeling Grid (CMG) (MCD12C1)](https://lpdaac.usgs.gov/products/mcd12c1v006/) product that indicate `Majority_Land_Cover_Type_1` is a cropland. The EVI is observed every 16 days.\n",
    "- `EVI_stacked.csv` is the same as `EVI.csv` except the data is stacked to include the EVI observations for each 16 days in the column.\n",
    "- `ERA5.csv` contains 2m temperature readings from [ERA5 Renalaysis](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land?tab=overview), \"the fifth generation ECMWF reanalysis for the global climate and weather for the past 4 to 7 decades\". More information about the variable can be found in the link given.\n",
    "\n",
    "**Recommended Reading:**\n",
    "- https://ojs.aaai.org/index.php/AAAI/article/view/11172/11031&hl=en&sa=T&oi=gsb-gga&ct=res&cd=0&d=1880767705414439608&ei=6kgwYPHHCvGTy9YPmJeAsAk&scisig=AAGBfm0LS8pg3jC6MJQQE5-vz3M2kSQeDg\n",
    "- https://aiforsocialgood.github.io/icml2019/accepted/track1/pdfs/20_aisg_icml2019.pdf\n",
    "- http://proceedings.mlr.press/v80/ilse18a/ilse18a.pdf\n",
    "- https://linkinghub.elsevier.com/retrieve/pii/S0034425711002926\n",
    "- https://linkinghub.elsevier.com/retrieve/pii/S0034425719304791\n",
    "- https://ieeexplore.ieee.org/document/9173550/\n",
    "- https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0510 \n",
    "- http://www.nature.com/articles/nclimate1832\n",
    "- http://www.nature.com/articles/nature16467\n",
    "- https://royalsocietypublishing.org/doi/10.1098/rstb.2019.0510\n",
    "\n",
    "**Suggestions:**\n",
    "\n",
    "- [ ] It will be useful to make use of `pandas`, `geopandas` and `matplotlib` for data processing and visualisation.\n",
    "- [ ] Be as creative and rigorous as possible with how you make use of the features.\n",
    "- [ ] Try and take some time to read through the various papers on the recommended reading list.\n",
    "- [ ] I recommend only using features between April - November 2015, as suggestioned by one of the papers on the list https://www.sciencedirect.com/science/article/pii/S0034425719304791?via%3Dihub. \n",
    "\n",
    "\n",
    "Good luck - we hope that you enjoy this challenge and look forward to seeing your submissions on Devpost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An illustrative plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import tensorflow\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('csv.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('crops_yield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"illinois-counties.geojson\")\n",
    "df = pd.read_csv(\"crops_yield/EVI_stacked.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df[df[\"year\"]==2015]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "gdf.plot(ax=ax, facecolor='none', edgecolor='red')\n",
    "\n",
    "plt.scatter(df_plot[\"long\"], df_plot[\"lat\"], c=df_plot[\"evi_1\"])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_crop = pd.read_csv(\"crops_yield/IL_yield.csv\")\n",
    "yield_crop = yield_crop[(yield_crop[\"year\"] > 2000)&(yield_crop[\"year\"] < 2020)]\n",
    "yield_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegetation = pd.read_csv(\"crops_yield/EVI_stacked.csv\")\n",
    "vegetation = vegetation[(vegetation[\"year\"]>1990)&(vegetation[\"year\"]<2020)]\n",
    "vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_yield = yield_crop[yield_crop[\"county\"]==\"MARION\"]\n",
    "yield_close = list(adam_yield[\"yield\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotted = vegetation[vegetation['county']==\"MARION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['evi_1','evi_17','evi_33','evi_49','evi_65','evi_81','evi_97','evi_113','evi_129','evi_145','evi_161','evi_177','evi_193','evi_209','evi_225','evi_241','evi_257','evi_273','evi_289','evi_305','evi_321','evi_337','evi_353']\n",
    "\n",
    "index = list(range(0,26))\n",
    "hello = []\n",
    "years = []\n",
    "\n",
    "j = 0\n",
    "for i in range(2001,2019):\n",
    "    add = list(plotted[plotted['year']==i].sum(axis=0))[4:27]\n",
    "    stuff = yield_close[j]\n",
    "    add.append(stuff)\n",
    "    newList = [i]+add\n",
    "    hello.append(newList)\n",
    "    j+=1\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['year','1','17','33','49','65','81','97','113','129','145','161','177','193','209','225','241','257','273','289','305','321','337','353','yield']\n",
    "df = pd.DataFrame(data = hello,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.filter(['yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = math.ceil(len(dataset)*.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = MinMaxScaler()\n",
    "normalised_data= norm.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalised_data[0:training_split,:]\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "\n",
    "for i in range(5, len(train_data)):\n",
    "    train_x.append(train_data[i-5:i,0])\n",
    "    train_y.append(train_data[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = np.array(train_x), np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x,(train_x.shape[0],train_x.shape[1],1))\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50,return_sequences = True, input_shape=(train_x.shape[1],1)))\n",
    "model.add(LSTM(50,return_sequences = False))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_y, batch_size = 5, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= normalised_data[training_split-5: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "y_test = dataset[training_split:,:]\n",
    "for i in range(5, len(test_data)):\n",
    "    test_x.append(test_data[i-5:i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.reshape(test_x,(test_x.shape[0],test_x.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)\n",
    "predictions = norm.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean((predictions-y_test)**2))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data[:training_split]\n",
    "# valid = data[training_split:]\n",
    "# valid['Predictions'] = predictions\n",
    "# plt.figure(figsize =(16,8))\n",
    "# plt.title('Model')\n",
    "# plt.xlabel('year',fontsize = 10)\n",
    "# plt.ylabel('Closing yield', fontsize = 10)\n",
    "# plt.plot(train['yield'])\n",
    "# plt.plot(valid[['yield', 'Predictions']])\n",
    "# plt.legend(['Train','Val','Predictions'],loc='lower right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
